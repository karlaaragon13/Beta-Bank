{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta - Bank ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Beta Bank está enfrentando un problema creciente de pérdida de clientes. Cada mes, más usuarios abandonan sus servicios, lo cual representa un costo importante para la institución. En respuesta, este proyecto tiene como objetivo desarrollar un modelo de machine learning capaz de predecir si un cliente abandonará el banco próximamente. Para ello, se utilizará un conjunto de datos con información demográfica y financiera de 10,000 clientes, incluyendo su historial de actividad. El modelo será evaluado principalmente con la métrica F1-score, buscando alcanzar un valor mínimo de 0.59 para su aprobación. Además, se analizará la métrica AUC-ROC para comparar su desempeño en términos de clasificación. A lo largo del proceso se abordará el problema del desbalance de clases y se implementarán distintas técnicas para mejorarlo.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción de los datos\n",
    "Puedes encontrar los datos en el archivo  /datasets/Churn.csv file. Descarga el conjunto de datos.\n",
    "\n",
    "Características: \n",
    "\n",
    "- RowNumber: índice de cadena de datos\n",
    "- CustomerId: identificador de cliente único\n",
    "- Surname: apellido\n",
    "- CreditScore: valor de crédito\n",
    "- Geography: país de residencia\n",
    "- Gender: sexo\n",
    "- Age: edad\n",
    "- Tenure: período durante el cual ha madurado el depósito a plazo fijo de un cliente (años)\n",
    "- Balance: saldo de la cuenta\n",
    "- NumOfProducts: número de productos bancarios utilizados por el cliente\n",
    "- HasCrCard: el cliente tiene una tarjeta de crédito (1 - sí; 0 - no)\n",
    "- IsActiveMember: actividad del cliente (1 - sí; 0 - no)\n",
    "- EstimatedSalary: salario estimado\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "- Exited: El cliente se ha ido (1 - sí; 0 - no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo\n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "# Visualizar los primeros registros\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`El conjunto de datos proporcionado por Beta Bank contiene información de 10,000 clientes, con un total de 14 columnas que incluyen datos demográficos, financieros y de comportamiento. Entre las variables destacan el puntaje de crédito (CreditScore), país de residencia (Geography), género (Gender), edad (Age), años de permanencia (Tenure), saldo en cuenta (Balance), número de productos contratados (NumOfProducts), si posee tarjeta de crédito (HasCrCard), si es un cliente activo (IsActiveMember) y el salario estimado (EstimatedSalary). La variable objetivo es Exited, que indica si el cliente abandonó el banco (1) o no (0).`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las variables que no aportan valor descriptivo \n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar valores asuentes de la columna Tenure con la mediana \n",
    "df['Tenure'].fillna(df['Tenure'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE para las variables categóricas : gender y geography \n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar la varible objetivo y las características \n",
    "features = df.drop('Exited', axis = 1)\n",
    "target = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos entrenamiento + validación y prueba\n",
    "fts_train_val, fts_test, tar_train_val, tar_test = train_test_split(features, target, test_size= 0.2, random_state = 54321)\n",
    "\n",
    "# Ahora dividimos entre entrenamiento y validación \n",
    "fts_train, fts_valid, tar_train, tar_valid = train_test_split(fts_train_val, tar_train_val, test_size = 0.25, random_state = 54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escalan las características\n",
    "scaler = StandardScaler()\n",
    "fts_train_scaled = scaler.fit_transform(fts_train)\n",
    "fts_valid_scaled = scaler.transform(fts_valid)\n",
    "fts_test_scaled = scaler.transform(fts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`En esta etapa se prepararon los datos para el entrenamiento de modelos. Primero se eliminaron columnas irrelevantes como RowNumber, CustomerId y Surname, ya que no aportan información predictiva. Se imputaron los valores faltantes en la columna Tenure usando la mediana. Posteriormente, se aplicó codificación one-hot a las variables categóricas (Geography y Gender), eliminando una categoría para evitar multicolinealidad. La variable objetivo (Exited) se separó de las características. Luego, el conjunto de datos fue dividido en tres partes: entrenamiento (60%), validación (20%) y prueba (20%). Finalmente, se aplicó escalado de características numéricas con StandardScaler, garantizando que todas las variables tuvieran la misma escala para mejorar el rendimiento de los algoritmos.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Base (sin correción del desequilibrio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Base:\n",
      "F1 Score (validación): 0.581\n",
      "AUC-ROC: 0.852\n",
      "Matriz de confusión:\n",
      " [[1485   73]\n",
      " [ 231  211]]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo \n",
    "model_base = RandomForestClassifier(random_state= 54321)\n",
    "model_base.fit(fts_train_scaled, tar_train)\n",
    "\n",
    "# Validación \n",
    "base_predicted = model_base.predict(fts_valid_scaled)\n",
    "\n",
    "# Evaluación \n",
    "f1_base = f1_score(tar_valid, base_predicted)\n",
    "roc_base = roc_auc_score(tar_valid, model_base.predict_proba(fts_valid_scaled)[:, 1])\n",
    "\n",
    "print('Modelo Base:')\n",
    "print(\"F1 Score (validación):\", round(f1_base, 3))\n",
    "print(\"AUC-ROC:\", round(roc_base, 3))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(tar_valid, base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`El modelo base, entrenado sin aplicar ninguna técnica para corregir el desbalance de clases, alcanzó un F1 Score de 0.581 en el conjunto de validación, ligeramente por debajo del umbral requerido de 0.59. Sin embargo, obtuvo una AUC-ROC de 0.852, lo cual indica que el modelo tiene una muy buena capacidad para distinguir entre clientes que abandonan y los que no. La matriz de confusión muestra que el modelo predijo correctamente a 1,485 clientes que se quedaron y a 211 que se fueron. Sin embargo, también cometió 231 falsos negativos, es decir, clientes que realmente abandonaron pero el modelo no los detectó. Esto sugiere que, aunque el modelo es bueno en términos generales (AUC-ROC), tiende a favorecer la clase mayoritaria (clientes que se quedan), lo cual es un comportamiento esperado cuando hay desequilibrio en los datos y no se corrige.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprobar desequilibrio de clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en todo el dataset:\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de clases en todo el dataset:\")\n",
    "print(target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Al analizar la variable objetivo (Exited), se observa un desequilibrio significativo en las clases: aproximadamente el 79.6% de los clientes permanecen en el banco (clase 0), mientras que solo el 20.4% lo abandonan (clase 1). Esta distribución desbalanceada puede afectar negativamente el rendimiento del modelo, ya que los algoritmos de clasificación tienden a favorecer la clase mayoritaria, resultando en una baja sensibilidad para detectar a los clientes que realmente se van. Por esta razón, es necesario aplicar técnicas de balanceo de clases durante el entrenamiento para mejorar la capacidad del modelo de identificar correctamente a los clientes en riesgo de abandono.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correción del desbalance -> Opción #1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Balanceado Opción 1:\n",
      "F1 Score (validación): 0.544\n",
      "AUC-ROC: 0.848\n",
      "Matriz de confusión:\n",
      " [[1500   58]\n",
      " [ 255  187]]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar de nuevo el modelo pero con la correción de clases opción 1 \n",
    "model_weighted_1 = RandomForestClassifier(random_state = 54321, class_weight='balanced')\n",
    "model_weighted_1.fit(fts_train_scaled, tar_train)\n",
    "\n",
    "# Validación \n",
    "w_predicted_1 = model_weighted_1.predict(fts_valid_scaled)\n",
    "\n",
    "# Evaluación \n",
    "f1_w_1 = f1_score(tar_valid, w_predicted_1)\n",
    "roc_w_1 = roc_auc_score(tar_valid, model_weighted_1.predict_proba(fts_valid_scaled)[:, 1])\n",
    "\n",
    "print('Modelo Balanceado Opción 1:')\n",
    "print(\"F1 Score (validación):\", round(f1_w_1, 3))\n",
    "print(\"AUC-ROC:\", round(roc_w_1, 3))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(tar_valid, w_predicted_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Al aplicar la primera técnica de corrección del desbalance mediante la asignación automática de pesos (class_weight='balanced'), el modelo logró un F1 Score de 0.544, ligeramente inferior al modelo base (0.581), y una AUC-ROC de 0.848, también apenas menor. La matriz de confusión muestra que el modelo detectó correctamente a 187 clientes que abandonaron el banco, pero aumentó el número de falsos negativos a 255. Aunque esta estrategia buscaba mejorar la detección de la clase minoritaria, en este caso no logró superar el rendimiento del modelo base, indicando que ajustar los pesos no fue suficiente para mejorar la capacidad del modelo de identificar a los clientes que se van.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correción del desbalance -> Opción #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Balanceado Opción 2:\n",
      "F1 Score (validación): 0.6\n",
      "AUC-ROC: 0.854\n",
      "Matriz de confusión:\n",
      " [[1216  342]\n",
      " [ 106  336]]\n"
     ]
    }
   ],
   "source": [
    "# Submuestreo\n",
    "def downsample(features, target, frac_majority):\n",
    "    # Alinear índices\n",
    "    features = features.reset_index(drop=True)\n",
    "    target = target.reset_index(drop=True)\n",
    "\n",
    "    # Separar clases\n",
    "    majority_class = features[target == 0]\n",
    "    minority_class = features[target == 1]\n",
    "    majority_target = target[target == 0]\n",
    "    minority_target = target[target == 1]\n",
    "\n",
    "    # Submuestreo de clase mayoritaria\n",
    "    majority_down = majority_class.sample(frac=frac_majority, random_state=54321)\n",
    "    majority_target_down = majority_target.loc[majority_down.index]\n",
    "\n",
    "    # Combinar datos balanceados\n",
    "    features_downsampled = pd.concat([majority_down, minority_class])\n",
    "    target_downsampled = pd.concat([majority_target_down, minority_target])\n",
    "\n",
    "    # Mezclar\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=54321\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Aplicar función\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    pd.DataFrame(fts_train_scaled, columns=fts_train.columns),\n",
    "    tar_train,\n",
    "    frac_majority=0.25\n",
    ")\n",
    "\n",
    "# Entrenar modelo\n",
    "model_weighted_2 = RandomForestClassifier(random_state=54321)\n",
    "model_weighted_2.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "# Validación\n",
    "w_predicted_2 = model_weighted_2.predict(fts_valid_scaled)\n",
    "\n",
    "# Evaluación\n",
    "f1_w_2 = f1_score(tar_valid, w_predicted_2)\n",
    "roc_w_2 = roc_auc_score(tar_valid, model_weighted_2.predict_proba(fts_valid_scaled)[:, 1])\n",
    "\n",
    "print('Modelo Balanceado Opción 2:')\n",
    "print(\"F1 Score (validación):\", round(f1_w_2, 3))\n",
    "print(\"AUC-ROC:\", round(roc_w_2, 3))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(tar_valid, w_predicted_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tras aplicar submuestreo para equilibrar las clases en el conjunto de entrenamiento, el modelo alcanzó un F1 Score de 0.60, superando el umbral mínimo requerido de 0.59, lo cual indica un buen equilibrio entre precisión y recall para la clase minoritaria. Además, obtuvo una AUC-ROC de 0.854, reflejando una muy buena capacidad de discriminación entre clases. La matriz de confusión muestra una mejora significativa en la detección de clientes que abandonan el banco (336 verdaderos positivos), con una reducción en los falsos negativos a 106, en comparación con modelos anteriores. Estos resultados sugieren que el submuestreo fue efectivo para mejorar la sensibilidad del modelo sin sacrificar mucho rendimiento general.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación final y selección del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen de modelos en validación:\n",
      "Modelo base         - F1: 0.581, AUC: 0.852\n",
      "Class_weight        - F1: 0.544, AUC: 0.848\n",
      "Submuestreo manual  - F1: 0.600, AUC: 0.854\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResumen de modelos en validación:\")\n",
    "print(f\"Modelo base         - F1: {f1_base:.3f}, AUC: {roc_base:.3f}\")\n",
    "print(f\"Class_weight        - F1: {f1_w_1:.3f}, AUC: {roc_w_1:.3f}\")\n",
    "print(f\"Submuestreo manual  - F1: {f1_w_2:.3f}, AUC: {roc_w_2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Se evaluaron tres enfoques distintos para el entrenamiento del modelo. El modelo base, sin corrección de desequilibrio, obtuvo un F1 Score de 0.581 y un AUC-ROC de 0.852, mostrando buena capacidad para distinguir clases, pero con tendencia a favorecer la clase mayoritaria. Al aplicar class_weight='balanced', el rendimiento del modelo disminuyó, con un F1 Score de 0.544 y AUC-ROC de 0.848, lo que sugiere que este ajuste no fue suficiente para mejorar la detección de clientes que abandonan. En cambio, el enfoque de submuestreo logró los mejores resultados, con un F1 Score de 0.600 y un AUC-ROC de 0.854, superando el umbral requerido. Este método mejoró el equilibrio entre precisión y recall, convirtiéndose en la mejor opción para predecir la pérdida de clientes.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba final con el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Balanceado Opción 2 con DataSet de Prueba\n",
      "F1 Score (validación): 0.605\n",
      "AUC-ROC: 0.868\n",
      "Matriz de confusión:\n",
      " [[1306  304]\n",
      " [  89  301]]\n"
     ]
    }
   ],
   "source": [
    "# Probar el mejor modelo con el dataset de prueba\n",
    "test_preds = model_weighted_2.predict(fts_test_scaled)\n",
    "\n",
    "# Evaluación final \n",
    "f1_final = f1_score(tar_test, test_preds)\n",
    "roc_final = roc_auc_score(tar_test, model_weighted_2.predict_proba(fts_test_scaled)[:, 1])\n",
    "\n",
    "print('Modelo Balanceado Opción 2 con DataSet de Prueba')\n",
    "print(\"F1 Score (validación):\", round(f1_final, 3))\n",
    "print(\"AUC-ROC:\", round(roc_final, 3))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(tar_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`El modelo seleccionado —entrenado con submuestreo— fue evaluado en el conjunto de prueba, alcanzando un F1 Score de 0.605, lo que confirma la consistencia y robustez del modelo, superando nuevamente el umbral mínimo requerido. Además, logró un AUC-ROC de 0.868, lo cual indica una muy buena capacidad de discriminación entre clientes que abandonan y los que permanecen. La matriz de confusión muestra que el modelo identificó correctamente a 301 clientes que abandonaron el banco y redujo los falsos negativos a solo 89, lo que es crucial para tomar acciones preventivas. Estos resultados validan que el modelo generaliza bien y es confiable para su uso en un entorno real.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` En este proyecto se desarrolló un modelo de machine learning para predecir la pérdida de clientes del Beta Bank, utilizando un conjunto de datos históricos con diversas características demográficas y financieras. Durante el análisis exploratorio, se identificó un desequilibrio significativo en las clases, por lo que se implementaron distintas estrategias para corregirlo: entrenamiento sin corrección (modelo base), ajuste de pesos (class_weight='balanced') y submuestreo manual de la clase mayoritaria. `\n",
    "\n",
    "`Tras comparar los resultados en el conjunto de validación, se determinó que el enfoque de submuestreo fue el más efectivo, al lograr el mejor balance entre precisión y recall, con un F1 Score de 0.600 y un AUC-ROC de 0.854. Finalmente, al evaluarlo en el conjunto de prueba, el modelo alcanzó un F1 Score de 0.605 y un AUC-ROC de 0.868, lo que demuestra su capacidad para generalizar y detectar correctamente a los clientes en riesgo de abandono.`\n",
    "\n",
    "`En conclusión, se logró desarrollar un modelo predictivo eficaz, que no solo supera el umbral mínimo requerido, sino que también ofrece una herramienta útil para que el banco tome decisiones informadas y proactivas para reducir la pérdida de clientes. `"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
